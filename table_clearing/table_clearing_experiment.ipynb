{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "import table_clearing_experiment_utils\n",
    "import utils\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "1099"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "include_trust_change = False\n",
    "query_action = True\n",
    "\n",
    "remaining_objects = {'plastic bottle': 3, 'fish can': 1, 'wine glass': 1}\n",
    "root_node = table_clearing_experiment_utils.Node(remaining_objects, [], include_trust_change=include_trust_change)\n",
    "\n",
    "if query_action:\n",
    "    template_generation_fn = table_clearing_experiment_utils.generate_template_action\n",
    "else:\n",
    "    template_generation_fn = table_clearing_experiment_utils.generate_template\n",
    "\n",
    "table_clearing_experiment_utils.expand_interaction_tree(root_node, template_generation_fn=template_generation_fn)\n",
    "all_nodes = root_node.traverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "answer_choices = [\"A\", \"B\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_header = ['remaining objects', 'history', 'prompt'] + answer_choices\n",
    "result_header.append('sum of prob')\n",
    "include_trust_change = False\n",
    "query_action = True\n",
    "descr = \"\"\n",
    "if include_trust_change:\n",
    "    descr += \"trust_change\"\n",
    "if query_action:\n",
    "    descr += \"_query_action\"\n",
    "else:\n",
    "    descr += \"_query_yesno\"\n",
    "    \n",
    "if query_action:\n",
    "    template_generation_fn = table_clearing_experiment_utils.generate_template_action\n",
    "else:\n",
    "    template_generation_fn = table_clearing_experiment_utils.generate_template\n",
    "\n",
    "llm_result_path = f\"./results/t5_{descr}.csv\"\n",
    "if not os.path.exists(llm_result_path):\n",
    "    max_memory = {0: \"20GIB\", 1: \"20GIB\", 2: \"20GIB\", 3: \"20GIB\"}\n",
    "    model = T5ForConditionalGeneration.from_pretrained(\"google/flan-t5-xxl\", device_map=\"auto\", max_memory=max_memory)\n",
    "    tokenizer = T5Tokenizer.from_pretrained(\"google/flan-t5-xxl\")\n",
    "    llm_result_file = open(llm_result_path, 'w')\n",
    "    writer = csv.writer(llm_result_file)\n",
    "    writer.writerow(result_header)\n",
    "\n",
    "    remaining_objects = {'plastic bottle': 3, 'fish can': 1, 'wine glass': 1}\n",
    "    root_node = table_clearing_experiment_utils.Node(remaining_objects, [], include_trust_change=include_trust_change)\n",
    "    table_clearing_experiment_utils.expand_interaction_tree(root_node, template_generation_fn=template_generation_fn)\n",
    "    all_nodes = root_node.traverse()\n",
    "    \n",
    "    print(f\"Saving to {llm_result_path}\")\n",
    "    print(f\"Include trust change {include_trust_change}, Query for {'yes no' if not query_action else 'action'}\")\n",
    "\n",
    "    for node in tqdm(all_nodes):\n",
    "        for prompt in node.prompts:\n",
    "            probs = utils.get_probs_t5([prompt], model, tokenizer, answer_choices)[0]\n",
    "            writer.writerow([node.remaining_objects, node.history, prompt, probs[0], probs[1], sum(probs)])\n",
    "    llm_result_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_header = ['remaining objects', 'history', 'prompt'] + answer_choices\n",
    "result_header.append('sum of prob')\n",
    "include_trust_change = False\n",
    "query_action = True\n",
    "descr = \"\"\n",
    "if include_trust_change:\n",
    "    descr += \"trust_change\"\n",
    "if query_action:\n",
    "    descr += \"_query_action\"\n",
    "else:\n",
    "    descr += \"_query_yesno\"\n",
    "    \n",
    "if query_action:\n",
    "    template_generation_fn = table_clearing_experiment_utils.generate_template_action\n",
    "else:\n",
    "    template_generation_fn = table_clearing_experiment_utils.generate_template\n",
    "\n",
    "llm_result_path = f\"./results/davinci_{descr}.csv\"\n",
    "if not os.path.exists(llm_result_path):\n",
    "    result_header = ['remaining objects', 'history', 'prompt'] + answer_choices\n",
    "    result_header.append('sum of prob')\n",
    "    llm_result_file = open(llm_result_path, 'w')\n",
    "    writer = csv.writer(llm_result_file)\n",
    "    writer.writerow(result_header)\n",
    "\n",
    "    remaining_objects = {'plastic bottle': 3, 'fish can': 1, 'wine glass': 1}\n",
    "    root_node = table_clearing_experiment_utils.Node(remaining_objects, [], include_trust_change=include_trust_change)\n",
    "    table_clearing_experiment_utils.expand_interaction_tree(root_node, template_generation_fn=template_generation_fn)\n",
    "    all_nodes = root_node.traverse()\n",
    "\n",
    "    print(f\"Saving to {llm_result_path}\")\n",
    "    print(f\"Include trust change {include_trust_change}, Query for {'yes no' if not query_action else 'action'}\")\n",
    "    \n",
    "    for node in tqdm(all_nodes):\n",
    "        for prompt in node.prompts:\n",
    "            template = prompt + \" {}\"\n",
    "            probs = utils.get_probs_davinci(template, answer_choices)\n",
    "            writer.writerow([node.remaining_objects, node.history, prompt, probs[0], probs[1], sum(probs)])\n",
    "    llm_result_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************** results ***********************\n",
      "#### return #####\n",
      "mean return:  6.1388581549909995\n",
      "std:  0.03358096569498668\n",
      "##### intervention ratio #####\n",
      "intervene ratio:  [0.07583333 0.2011     0.3603    ]\n",
      "./results/davinci__query_action.csv\n",
      "*************** results ***********************\n",
      "#### return #####\n",
      "mean return:  6.138182573410001\n",
      "std:  0.03411672375918422\n",
      "##### intervention ratio #####\n",
      "intervene ratio:  [0.07833333 0.1944     0.3628    ]\n",
      "./results/davinci__query_yesno.csv\n",
      "*************** results ***********************\n",
      "#### return #####\n",
      "mean return:  6.148677582649\n",
      "std:  0.03380614817922158\n",
      "##### intervention ratio #####\n",
      "intervene ratio:  [0.07413333 0.2114     0.3517    ]\n",
      "./results/davinci_trust_change_query_action.csv\n",
      "*************** results ***********************\n",
      "#### return #####\n",
      "mean return:  6.173598900674001\n",
      "std:  0.033996323440301617\n",
      "##### intervention ratio #####\n",
      "intervene ratio:  [0.07443333 0.1975     0.3523    ]\n",
      "./results/davinci_trust_change_query_yesno.csv\n",
      "*************** results ***********************\n",
      "#### return #####\n",
      "mean return:  5.938629767586\n",
      "std:  0.03452810445057588\n",
      "##### intervention ratio #####\n",
      "intervene ratio:  [0.08686667 0.235      0.4072    ]\n",
      "./results/t5__query_action.csv\n",
      "*************** results ***********************\n",
      "#### return #####\n",
      "mean return:  5.999293996146999\n",
      "std:  0.034558677121693845\n",
      "##### intervention ratio #####\n",
      "intervene ratio:  [0.08273333 0.2158     0.4012    ]\n",
      "./results/t5__query_yesno.csv\n",
      "*************** results ***********************\n",
      "#### return #####\n",
      "mean return:  5.955086360666\n",
      "std:  0.034559097890777275\n",
      "##### intervention ratio #####\n",
      "intervene ratio:  [0.0843 0.2403 0.3999]\n",
      "./results/t5_trust_change_query_action.csv\n",
      "*************** results ***********************\n",
      "#### return #####\n",
      "mean return:  6.107589874315\n",
      "std:  0.03439736866354319\n",
      "##### intervention ratio #####\n",
      "intervene ratio:  [0.07523333 0.2158     0.3646    ]\n",
      "./results/t5_trust_change_query_yesno.csv\n"
     ]
    }
   ],
   "source": [
    "# Evaluate different policies in the simulated environment\n",
    "# Note that the davinci policies are not very distinguishable\n",
    "for csv_path in sorted(os.listdir('./results')):\n",
    "    # csv_path = 'davinci_trust_change_query_yesno.csv'\n",
    "    table_clearing_experiment_utils.evaluate_policy(f'./results/{csv_path}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e1440383828611d8fed5d8091af4c473109f9ffafed453bfa3d9e353f9b9aeb7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
